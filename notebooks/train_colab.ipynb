{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Tiny Recursive Model (TRM) Training on Colab\n",
                "\n",
                "This notebook guides you through setting up and training the TRM on Google Colab."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup\n",
                "\n",
                "First, we need to clone the repository and install the dependencies."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!git clone https://github.com/dauvannam1804/TinyRecursiveModels.git\n",
                "%cd TinyRecursiveModels\n",
                "!pip install -r requirements.txt"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Generate Data\n",
                "\n",
                "Generate training (20k) and validation (5k) datasets."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!python create_sample.py"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Train Tokenizer\n",
                "\n",
                "We need to train a custom tokenizer on our dataset. This script will use the `data/processed/sample_1k.csv` by default."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!chmod +x scripts/train_tokenizer.sh\n",
                "!./scripts/train_tokenizer.sh"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Train Model\n",
                "\n",
                "Now we can start training the model. You can adjust configurations in `src/config.py` if needed."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!chmod +x scripts/run_train.sh\n",
                "!./scripts/run_train.sh"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
<<<<<<< HEAD
                "## 4. Plot Training Results\n",
=======
                "## 5. Plot Results\n",
>>>>>>> c507be9608c04a9c58e2cdc9274930fbb06d907f
                "\n",
                "Visualize the training and validation loss."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import matplotlib.pyplot as plt\n",
                "import os\n",
                "\n",
                "history_path = \"checkpoints/history.json\"\n",
<<<<<<< HEAD
                "\n",
                "if os.path.exists(history_path):\n",
                "    with open(history_path, \"r\") as f:\n",
                "        history = json.load(f)\n",
                "    \n",
                "    plt.figure(figsize=(10, 6))\n",
                "    plt.plot(history[\"train_loss\"], label=\"Train Loss\")\n",
                "    if any(history[\"val_loss\"]):\n",
                "        plt.plot(history[\"val_loss\"], label=\"Val Loss\")\n",
                "    plt.xlabel(\"Epoch\")\n",
                "    plt.ylabel(\"Loss\")\n",
                "    plt.title(\"Training History\")\n",
                "    plt.legend()\n",
                "    plt.grid(True)\n",
                "    plt.show()\n",
                "else:\n",
                "    print(\"History file not found. Make sure training completed successfully.\")"
=======
                "if os.path.exists(history_path):\n",
                "    with open(history_path, \"r\") as f:\n",
                "        history = json.load(f)\n",
                "\n",
                "    plt.figure(figsize=(10, 5))\n",
                "    plt.plot(history[\"train_loss\"], label=\"Train Loss\")\n",
                "    plt.plot(history[\"val_loss\"], label=\"Val Loss\")\n",
                "    plt.xlabel(\"Epoch\")\n",
                "    plt.ylabel(\"Loss\")\n",
                "    plt.legend()\n",
                "    plt.title(\"Training and Validation Loss\")\n",
                "    plt.show()\n",
                "else:\n",
                "    print(\"History file not found. Train the model first.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Check Parameter Count\n",
                "\n",
                "Verify the model size."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.model import TinyRecursiveModel\n",
                "from src.config import Config\n",
                "\n",
                "config = Config()\n",
                "model = TinyRecursiveModel(config.model)\n",
                "\n",
                "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
                "print(f\"Total Trainable Parameters: {total_params:,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Inference Demo (Real Data)\n",
                "\n",
                "Load a sample from the validation set and test the model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.inference import InferenceEngine\n",
                "import json\n",
                "import os\n",
                "import random\n",
                "\n",
                "# Find latest checkpoint\n",
                "checkpoint_dir = \"checkpoints\"\n",
                "latest_checkpoint = None\n",
                "if os.path.exists(checkpoint_dir):\n",
                "    checkpoints = [f for f in os.listdir(checkpoint_dir) if f.endswith(\".pt\")]\n",
                "    if checkpoints:\n",
                "        # Sort by epoch number assuming format 'checkpoint_epoch_X.pt'\n",
                "        checkpoints.sort(key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
                "        latest_checkpoint = os.path.join(checkpoint_dir, checkpoints[-1])\n",
                "        print(f\"Using checkpoint: {latest_checkpoint}\")\n",
                "\n",
                "if latest_checkpoint:\n",
                "    engine = InferenceEngine(checkpoint_path=latest_checkpoint)\n",
                "    \n",
                "    # Load validation data (XLAM JSON)\n",
                "    val_path = \"data/processed/xlam_val_200_swift.json\"\n",
                "    if os.path.exists(val_path):\n",
                "        with open(val_path, 'r') as f:\n",
                "            data = json.load(f)\n",
                "        \n",
                "        # Pick a random sample\n",
                "        item = random.choice(data)\n",
                "        tools = item[\"tools\"]\n",
                "        query = \"\"\n",
                "        ground_truth = \"\"\n",
                "        \n",
                "        for msg in item[\"messages\"]:\n",
                "            if msg[\"role\"] == \"user\":\n",
                "                query = msg[\"content\"]\n",
                "            elif msg[\"role\"] == \"tool_call\":\n",
                "                ground_truth = msg[\"content\"]\n",
                "        \n",
                "        print(\"-\" * 50)\n",
                "        print(f\"QUERY:\\n{query}\")\n",
                "        print(\"-\" * 50)\n",
                "        \n",
                "        # Generate Tool Call\n",
                "        prediction = engine.generate_tool_call(tools, query)\n",
                "        \n",
                "        # Extract just the generated part (simple heuristic for demo)\n",
                "        # In real usage, we'd parse the output\n",
                "        print(f\"MODEL OUTPUT (Full):\\n{prediction}\")\n",
                "        print(\"-\" * 50)\n",
                "        print(f\"GROUND TRUTH:\\n{ground_truth}\")\n",
                "        print(\"-\" * 50)\n",
                "        \n",
                "    else:\n",
                "        print(f\"Validation file not found at {val_path}. Please generate data first.\")\n",
                "\n",
                "else:\n",
                "    print(\"No checkpoint found. Please train the model first.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "61711023",
            "metadata": {},
            "source": [
                "## 8. Evaluate Accuracy\n",
                "\n",
                "Calculate Exact Match accuracy on the validation set."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e36eb177",
            "metadata": {},
            "outputs": [],
            "source": [
                "if latest_checkpoint and os.path.exists(\"data/processed/xlam_val_200_swift.json\"):\n",
                "    print(\"Evaluating Accuracy...\")\n",
                "    engine.evaluate_dataset(\"data/processed/xlam_val_200_swift.json\")\n",
                "else:\n",
                "    print(\"Cannot evaluate. Checkpoint or validation data missing.\")"
>>>>>>> c507be9608c04a9c58e2cdc9274930fbb06d907f
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}